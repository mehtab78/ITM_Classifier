{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V5E1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://mehtab78: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@github.com/mehtab78/ITM_Classifier.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9y8VcVEYcIBQ",
        "outputId": "12c4c83c-6d90-4477-ad69-976b53987d50"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ITM_Classifier'...\n",
            "remote: Enumerating objects: 6427, done.\u001b[K\n",
            "remote: Counting objects: 100% (56/56), done.\u001b[K\n",
            "remote: Compressing objects: 100% (37/37), done.\u001b[K\n",
            "remote: Total 6427 (delta 35), reused 39 (delta 19), pack-reused 6371 (from 1)\u001b[K\n",
            "Receiving objects: 100% (6427/6427), 212.66 MiB | 48.70 MiB/s, done.\n",
            "Resolving deltas: 100% (39/39), done.\n",
            "Updating files: 100% (6365/6365), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ITM_Classifier/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODSway7qeMXR",
        "outputId": "d61cbd4a-9cbe-48fb-a438-835a2a0b27ce"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ITM_Classifier\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 main.py --arch CNN --pretrained --epochs 5 --batch_size 16"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-h5QDLnCsElx",
        "outputId": "fe7828e1-ae05-4470-cbbe-7739eed6d5d8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading sentence embeddings...\n",
            "READING sentence embeddings...\n",
            "Preparing datasets and dataloaders...\n",
            "LOADING data from v7w.TrainImages.itm.txt\n",
            "=========================================\n",
            "|image_data|=48904\n",
            "|question_data|=48904\n",
            "|answer_data|=48904\n",
            "done loading data...\n",
            "LOADING data from v7w.TestImages.itm.txt\n",
            "=========================================\n",
            "|image_data|=5980\n",
            "|question_data|=5980\n",
            "|answer_data|=5980\n",
            "done loading data...\n",
            "Initializing model...\n",
            "BUILDING CNN model, pretrained=True\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100% 44.7M/44.7M [00:00<00:00, 110MB/s]\n",
            "Starting training...\n",
            "TRAINING CNN model\n",
            "Epoch [1/5], Batch [0/3057], Loss: 0.5969\n",
            "Epoch [1/5], Batch [100/3057], Loss: 0.6128\n",
            "Epoch [1/5], Batch [200/3057], Loss: 0.4922\n",
            "Epoch [1/5], Batch [300/3057], Loss: 0.6146\n",
            "Epoch [1/5], Batch [400/3057], Loss: 0.5696\n",
            "Epoch [1/5], Batch [500/3057], Loss: 0.5677\n",
            "Epoch [1/5], Batch [600/3057], Loss: 0.4089\n",
            "Epoch [1/5], Batch [700/3057], Loss: 0.5081\n",
            "Epoch [1/5], Batch [800/3057], Loss: 0.5102\n",
            "Epoch [1/5], Batch [900/3057], Loss: 0.4915\n",
            "Epoch [1/5], Batch [1000/3057], Loss: 0.5394\n",
            "Epoch [1/5], Batch [1100/3057], Loss: 0.5435\n",
            "Epoch [1/5], Batch [1200/3057], Loss: 0.6742\n",
            "Epoch [1/5], Batch [1300/3057], Loss: 0.4869\n",
            "Epoch [1/5], Batch [1400/3057], Loss: 0.7224\n",
            "Epoch [1/5], Batch [1500/3057], Loss: 0.6036\n",
            "Epoch [1/5], Batch [1600/3057], Loss: 0.5256\n",
            "Epoch [1/5], Batch [1700/3057], Loss: 0.5948\n",
            "Epoch [1/5], Batch [1800/3057], Loss: 0.6710\n",
            "Epoch [1/5], Batch [1900/3057], Loss: 0.5110\n",
            "Epoch [1/5], Batch [2000/3057], Loss: 0.7750\n",
            "Epoch [1/5], Batch [2100/3057], Loss: 0.5661\n",
            "Epoch [1/5], Batch [2200/3057], Loss: 0.3228\n",
            "Epoch [1/5], Batch [2300/3057], Loss: 0.3475\n",
            "Epoch [1/5], Batch [2400/3057], Loss: 0.5118\n",
            "Epoch [1/5], Batch [2500/3057], Loss: 0.5034\n",
            "Epoch [1/5], Batch [2600/3057], Loss: 0.3925\n",
            "Epoch [1/5], Batch [2700/3057], Loss: 0.6224\n",
            "Epoch [1/5], Batch [2800/3057], Loss: 0.7798\n",
            "Epoch [1/5], Batch [2900/3057], Loss: 0.3670\n",
            "Epoch [1/5], Batch [3000/3057], Loss: 0.8093\n",
            "Epoch [1/5] Average Loss: 0.5234, 524.69 seconds\n",
            "Epoch [2/5], Batch [0/3057], Loss: 0.7565\n",
            "Epoch [2/5], Batch [100/3057], Loss: 0.4195\n",
            "Epoch [2/5], Batch [200/3057], Loss: 0.3100\n",
            "Epoch [2/5], Batch [300/3057], Loss: 0.3217\n",
            "Epoch [2/5], Batch [400/3057], Loss: 0.4648\n",
            "Epoch [2/5], Batch [500/3057], Loss: 0.5928\n",
            "Epoch [2/5], Batch [600/3057], Loss: 0.4860\n",
            "Epoch [2/5], Batch [700/3057], Loss: 0.5222\n",
            "Epoch [2/5], Batch [800/3057], Loss: 0.5015\n",
            "Epoch [2/5], Batch [900/3057], Loss: 0.2883\n",
            "Epoch [2/5], Batch [1000/3057], Loss: 0.3034\n",
            "Epoch [2/5], Batch [1100/3057], Loss: 0.4657\n",
            "Epoch [2/5], Batch [1200/3057], Loss: 0.5655\n",
            "Epoch [2/5], Batch [1300/3057], Loss: 0.3079\n",
            "Epoch [2/5], Batch [1400/3057], Loss: 0.4700\n",
            "Epoch [2/5], Batch [1500/3057], Loss: 0.5361\n",
            "Epoch [2/5], Batch [1600/3057], Loss: 0.4471\n",
            "Epoch [2/5], Batch [1700/3057], Loss: 0.5001\n",
            "Epoch [2/5], Batch [1800/3057], Loss: 0.3601\n",
            "Epoch [2/5], Batch [1900/3057], Loss: 0.4144\n",
            "Epoch [2/5], Batch [2000/3057], Loss: 0.5736\n",
            "Epoch [2/5], Batch [2100/3057], Loss: 0.5383\n",
            "Epoch [2/5], Batch [2200/3057], Loss: 0.3899\n",
            "Epoch [2/5], Batch [2300/3057], Loss: 0.3139\n",
            "Epoch [2/5], Batch [2400/3057], Loss: 0.2858\n",
            "Epoch [2/5], Batch [2500/3057], Loss: 0.6775\n",
            "Epoch [2/5], Batch [2600/3057], Loss: 0.2808\n",
            "Epoch [2/5], Batch [2700/3057], Loss: 0.5217\n",
            "Epoch [2/5], Batch [2800/3057], Loss: 0.2380\n",
            "Epoch [2/5], Batch [2900/3057], Loss: 0.3827\n",
            "Epoch [2/5], Batch [3000/3057], Loss: 0.4956\n",
            "Epoch [2/5] Average Loss: 0.4643, 537.25 seconds\n",
            "Epoch [3/5], Batch [0/3057], Loss: 0.3469\n",
            "Epoch [3/5], Batch [100/3057], Loss: 0.7592\n",
            "Epoch [3/5], Batch [200/3057], Loss: 0.6552\n",
            "Epoch [3/5], Batch [300/3057], Loss: 0.4091\n",
            "Epoch [3/5], Batch [400/3057], Loss: 0.5782\n",
            "Epoch [3/5], Batch [500/3057], Loss: 0.3816\n",
            "Epoch [3/5], Batch [600/3057], Loss: 0.4853\n",
            "Epoch [3/5], Batch [700/3057], Loss: 0.4530\n",
            "Epoch [3/5], Batch [800/3057], Loss: 0.5270\n",
            "Epoch [3/5], Batch [900/3057], Loss: 0.4488\n",
            "Epoch [3/5], Batch [1000/3057], Loss: 0.4558\n",
            "Epoch [3/5], Batch [1100/3057], Loss: 0.6426\n",
            "Epoch [3/5], Batch [1200/3057], Loss: 0.5848\n",
            "Epoch [3/5], Batch [1300/3057], Loss: 0.4604\n",
            "Epoch [3/5], Batch [1400/3057], Loss: 0.5730\n",
            "Epoch [3/5], Batch [1500/3057], Loss: 0.4459\n",
            "Epoch [3/5], Batch [1600/3057], Loss: 0.4452\n",
            "Epoch [3/5], Batch [1700/3057], Loss: 0.2733\n",
            "Epoch [3/5], Batch [1800/3057], Loss: 0.7366\n",
            "Epoch [3/5], Batch [1900/3057], Loss: 0.5638\n",
            "Epoch [3/5], Batch [2000/3057], Loss: 0.4010\n",
            "Epoch [3/5], Batch [2100/3057], Loss: 0.5834\n",
            "Epoch [3/5], Batch [2200/3057], Loss: 0.4506\n",
            "Epoch [3/5], Batch [2300/3057], Loss: 0.4373\n",
            "Epoch [3/5], Batch [2400/3057], Loss: 0.4676\n",
            "Epoch [3/5], Batch [2500/3057], Loss: 0.3673\n",
            "Epoch [3/5], Batch [2600/3057], Loss: 0.3956\n",
            "Epoch [3/5], Batch [2700/3057], Loss: 0.5442\n",
            "Epoch [3/5], Batch [2800/3057], Loss: 0.3780\n",
            "Epoch [3/5], Batch [2900/3057], Loss: 0.4237\n",
            "Epoch [3/5], Batch [3000/3057], Loss: 0.3409\n",
            "Epoch [3/5] Average Loss: 0.4504, 535.78 seconds\n",
            "Epoch [4/5], Batch [0/3057], Loss: 0.3277\n",
            "Epoch [4/5], Batch [100/3057], Loss: 0.3599\n",
            "Epoch [4/5], Batch [200/3057], Loss: 0.4248\n",
            "Epoch [4/5], Batch [300/3057], Loss: 0.3216\n",
            "Epoch [4/5], Batch [400/3057], Loss: 0.6121\n",
            "Epoch [4/5], Batch [500/3057], Loss: 0.3594\n",
            "Epoch [4/5], Batch [600/3057], Loss: 0.4781\n",
            "Epoch [4/5], Batch [700/3057], Loss: 0.3249\n",
            "Epoch [4/5], Batch [800/3057], Loss: 0.3607\n",
            "Epoch [4/5], Batch [900/3057], Loss: 0.4266\n",
            "Epoch [4/5], Batch [1000/3057], Loss: 0.4739\n",
            "Epoch [4/5], Batch [1100/3057], Loss: 0.4674\n",
            "Epoch [4/5], Batch [1200/3057], Loss: 0.4049\n",
            "Epoch [4/5], Batch [1300/3057], Loss: 0.5642\n",
            "Epoch [4/5], Batch [1400/3057], Loss: 0.4901\n",
            "Epoch [4/5], Batch [1500/3057], Loss: 0.3886\n",
            "Epoch [4/5], Batch [1600/3057], Loss: 0.5024\n",
            "Epoch [4/5], Batch [1700/3057], Loss: 0.5250\n",
            "Epoch [4/5], Batch [1800/3057], Loss: 0.2998\n",
            "Epoch [4/5], Batch [1900/3057], Loss: 0.8059\n",
            "Epoch [4/5], Batch [2000/3057], Loss: 0.5761\n",
            "Epoch [4/5], Batch [2100/3057], Loss: 0.5831\n",
            "Epoch [4/5], Batch [2200/3057], Loss: 0.2762\n",
            "Epoch [4/5], Batch [2300/3057], Loss: 0.5378\n",
            "Epoch [4/5], Batch [2400/3057], Loss: 0.3039\n",
            "Epoch [4/5], Batch [2500/3057], Loss: 0.3653\n",
            "Epoch [4/5], Batch [2600/3057], Loss: 0.6498\n",
            "Epoch [4/5], Batch [2700/3057], Loss: 0.5708\n",
            "Epoch [4/5], Batch [2800/3057], Loss: 0.4300\n",
            "Epoch [4/5], Batch [2900/3057], Loss: 0.3307\n",
            "Epoch [4/5], Batch [3000/3057], Loss: 0.5871\n",
            "Epoch [4/5] Average Loss: 0.4437, 526.04 seconds\n",
            "Epoch [5/5], Batch [0/3057], Loss: 0.4555\n",
            "Epoch [5/5], Batch [100/3057], Loss: 0.3597\n",
            "Epoch [5/5], Batch [200/3057], Loss: 0.5472\n",
            "Epoch [5/5], Batch [300/3057], Loss: 0.3947\n",
            "Epoch [5/5], Batch [400/3057], Loss: 0.2089\n",
            "Epoch [5/5], Batch [500/3057], Loss: 0.3729\n",
            "Epoch [5/5], Batch [600/3057], Loss: 0.4913\n",
            "Epoch [5/5], Batch [700/3057], Loss: 0.4868\n",
            "Epoch [5/5], Batch [800/3057], Loss: 0.3073\n",
            "Epoch [5/5], Batch [900/3057], Loss: 0.4611\n",
            "Epoch [5/5], Batch [1000/3057], Loss: 0.4369\n",
            "Epoch [5/5], Batch [1100/3057], Loss: 0.6021\n",
            "Epoch [5/5], Batch [1200/3057], Loss: 0.3574\n",
            "Epoch [5/5], Batch [1300/3057], Loss: 0.5238\n",
            "Epoch [5/5], Batch [1400/3057], Loss: 0.5412\n",
            "Epoch [5/5], Batch [1500/3057], Loss: 0.4188\n",
            "Epoch [5/5], Batch [1600/3057], Loss: 0.4335\n",
            "Epoch [5/5], Batch [1700/3057], Loss: 0.6345\n",
            "Epoch [5/5], Batch [1800/3057], Loss: 0.6418\n",
            "Epoch [5/5], Batch [1900/3057], Loss: 0.3954\n",
            "Epoch [5/5], Batch [2000/3057], Loss: 0.3522\n",
            "Epoch [5/5], Batch [2100/3057], Loss: 0.1998\n",
            "Epoch [5/5], Batch [2200/3057], Loss: 0.8273\n",
            "Epoch [5/5], Batch [2300/3057], Loss: 0.5405\n",
            "Epoch [5/5], Batch [2400/3057], Loss: 0.3031\n",
            "Epoch [5/5], Batch [2500/3057], Loss: 0.5019\n",
            "Epoch [5/5], Batch [2600/3057], Loss: 0.4005\n",
            "Epoch [5/5], Batch [2700/3057], Loss: 0.4708\n",
            "Epoch [5/5], Batch [2800/3057], Loss: 0.4313\n",
            "Epoch [5/5], Batch [2900/3057], Loss: 0.3735\n",
            "Epoch [5/5], Batch [3000/3057], Loss: 0.3742\n",
            "Epoch [5/5] Average Loss: 0.4388, 528.99 seconds\n",
            "Training completed.\n",
            "Evaluating model...\n",
            "EVALUATING CNN model\n",
            "✅ Accuracy: 0.8043 | MRR: 0.7847 | Test Time: 58.82s\n",
            "📊 Results logged to results.csv\n",
            "✅ Model saved as itm_model_cnn.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 main.py --arch ViT --pretrained --epochs 5 --batch_size 16"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lG1rxIp9z7ww",
        "outputId": "a0473b19-337b-45d4-9a76-52d03ba34097"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading sentence embeddings...\n",
            "READING sentence embeddings...\n",
            "Preparing datasets and dataloaders...\n",
            "LOADING data from v7w.TrainImages.itm.txt\n",
            "=========================================\n",
            "|image_data|=48904\n",
            "|question_data|=48904\n",
            "|answer_data|=48904\n",
            "done loading data...\n",
            "LOADING data from v7w.TestImages.itm.txt\n",
            "=========================================\n",
            "|image_data|=5980\n",
            "|question_data|=5980\n",
            "|answer_data|=5980\n",
            "done loading data...\n",
            "Initializing model...\n",
            "BUILDING ViT model, pretrained=True\n",
            "Downloading: \"https://download.pytorch.org/models/vit_b_32-d86f8d99.pth\" to /root/.cache/torch/hub/checkpoints/vit_b_32-d86f8d99.pth\n",
            "100% 337M/337M [00:03<00:00, 113MB/s]\n",
            "Starting training...\n",
            "TRAINING ViT model\n",
            "Epoch [1/5], Batch [0/3057], Loss: 0.6995\n",
            "Epoch [1/5], Batch [100/3057], Loss: 0.5717\n",
            "Epoch [1/5], Batch [200/3057], Loss: 0.6172\n",
            "Epoch [1/5], Batch [300/3057], Loss: 0.5630\n",
            "Epoch [1/5], Batch [400/3057], Loss: 0.7614\n",
            "Epoch [1/5], Batch [500/3057], Loss: 0.5013\n",
            "Epoch [1/5], Batch [600/3057], Loss: 0.6248\n",
            "Epoch [1/5], Batch [700/3057], Loss: 0.5177\n",
            "Epoch [1/5], Batch [800/3057], Loss: 0.5558\n",
            "Epoch [1/5], Batch [900/3057], Loss: 0.6950\n",
            "Epoch [1/5], Batch [1000/3057], Loss: 0.4884\n",
            "Epoch [1/5], Batch [1100/3057], Loss: 0.4966\n",
            "Epoch [1/5], Batch [1200/3057], Loss: 0.5459\n",
            "Epoch [1/5], Batch [1300/3057], Loss: 0.6178\n",
            "Epoch [1/5], Batch [1400/3057], Loss: 0.6211\n",
            "Epoch [1/5], Batch [1500/3057], Loss: 0.5805\n",
            "Epoch [1/5], Batch [1600/3057], Loss: 0.3887\n",
            "Epoch [1/5], Batch [1700/3057], Loss: 0.8312\n",
            "Epoch [1/5], Batch [1800/3057], Loss: 0.3276\n",
            "Epoch [1/5], Batch [1900/3057], Loss: 0.7599\n",
            "Epoch [1/5], Batch [2000/3057], Loss: 0.5232\n",
            "Epoch [1/5], Batch [2100/3057], Loss: 0.5132\n",
            "Epoch [1/5], Batch [2200/3057], Loss: 0.3612\n",
            "Epoch [1/5], Batch [2300/3057], Loss: 0.4438\n",
            "Epoch [1/5], Batch [2400/3057], Loss: 0.5236\n",
            "Epoch [1/5], Batch [2500/3057], Loss: 0.2707\n",
            "Epoch [1/5], Batch [2600/3057], Loss: 0.2741\n",
            "Epoch [1/5], Batch [2700/3057], Loss: 0.4861\n",
            "Epoch [1/5], Batch [2800/3057], Loss: 0.6061\n",
            "Epoch [1/5], Batch [2900/3057], Loss: 0.3418\n",
            "Epoch [1/5], Batch [3000/3057], Loss: 0.6982\n",
            "Epoch [1/5] Average Loss: 0.5330, 943.22 seconds\n",
            "Epoch [2/5], Batch [0/3057], Loss: 0.3839\n",
            "Epoch [2/5], Batch [100/3057], Loss: 0.5489\n",
            "Epoch [2/5], Batch [200/3057], Loss: 0.5201\n",
            "Epoch [2/5], Batch [300/3057], Loss: 0.6106\n",
            "Epoch [2/5], Batch [400/3057], Loss: 0.4573\n",
            "Epoch [2/5], Batch [500/3057], Loss: 0.3616\n",
            "Epoch [2/5], Batch [600/3057], Loss: 0.4206\n",
            "Epoch [2/5], Batch [700/3057], Loss: 0.3993\n",
            "Epoch [2/5], Batch [800/3057], Loss: 0.3996\n",
            "Epoch [2/5], Batch [900/3057], Loss: 0.4856\n",
            "Epoch [2/5], Batch [1000/3057], Loss: 0.4499\n",
            "Epoch [2/5], Batch [1100/3057], Loss: 0.6306\n",
            "Epoch [2/5], Batch [1200/3057], Loss: 0.3352\n",
            "Epoch [2/5], Batch [1300/3057], Loss: 0.5585\n",
            "Epoch [2/5], Batch [1400/3057], Loss: 0.4763\n",
            "Epoch [2/5], Batch [1500/3057], Loss: 0.3441\n",
            "Epoch [2/5], Batch [1600/3057], Loss: 0.3751\n",
            "Epoch [2/5], Batch [1700/3057], Loss: 0.5713\n",
            "Epoch [2/5], Batch [1800/3057], Loss: 0.4669\n",
            "Epoch [2/5], Batch [1900/3057], Loss: 0.7439\n",
            "Epoch [2/5], Batch [2000/3057], Loss: 0.3951\n",
            "Epoch [2/5], Batch [2100/3057], Loss: 0.4127\n",
            "Epoch [2/5], Batch [2200/3057], Loss: 0.3867\n",
            "Epoch [2/5], Batch [2300/3057], Loss: 0.4130\n",
            "Epoch [2/5], Batch [2400/3057], Loss: 0.3550\n",
            "Epoch [2/5], Batch [2500/3057], Loss: 0.4212\n",
            "Epoch [2/5], Batch [2600/3057], Loss: 0.3770\n",
            "Epoch [2/5], Batch [2700/3057], Loss: 0.2598\n",
            "Epoch [2/5], Batch [2800/3057], Loss: 0.3206\n",
            "Epoch [2/5], Batch [2900/3057], Loss: 0.3558\n",
            "Epoch [2/5], Batch [3000/3057], Loss: 0.3938\n",
            "Epoch [2/5] Average Loss: 0.4696, 942.93 seconds\n",
            "Epoch [3/5], Batch [0/3057], Loss: 0.4714\n",
            "Epoch [3/5], Batch [100/3057], Loss: 0.3079\n",
            "Epoch [3/5], Batch [200/3057], Loss: 0.4427\n",
            "Epoch [3/5], Batch [300/3057], Loss: 0.3567\n",
            "Epoch [3/5], Batch [400/3057], Loss: 0.4139\n",
            "Epoch [3/5], Batch [500/3057], Loss: 0.4367\n",
            "Epoch [3/5], Batch [600/3057], Loss: 0.3001\n",
            "Epoch [3/5], Batch [700/3057], Loss: 0.4334\n",
            "Epoch [3/5], Batch [800/3057], Loss: 0.4790\n",
            "Epoch [3/5], Batch [900/3057], Loss: 0.3481\n",
            "Epoch [3/5], Batch [1000/3057], Loss: 0.2734\n",
            "Epoch [3/5], Batch [1100/3057], Loss: 0.3018\n",
            "Epoch [3/5], Batch [1200/3057], Loss: 0.1965\n",
            "Epoch [3/5], Batch [1300/3057], Loss: 0.4329\n",
            "Epoch [3/5], Batch [1400/3057], Loss: 0.3466\n",
            "Epoch [3/5], Batch [1500/3057], Loss: 0.2777\n",
            "Epoch [3/5], Batch [1600/3057], Loss: 0.3383\n",
            "Epoch [3/5], Batch [1700/3057], Loss: 0.4881\n",
            "Epoch [3/5], Batch [1800/3057], Loss: 0.2654\n",
            "Epoch [3/5], Batch [1900/3057], Loss: 0.3352\n",
            "Epoch [3/5], Batch [2000/3057], Loss: 0.5101\n",
            "Epoch [3/5], Batch [2100/3057], Loss: 0.4433\n",
            "Epoch [3/5], Batch [2200/3057], Loss: 0.3409\n",
            "Epoch [3/5], Batch [2300/3057], Loss: 0.5743\n",
            "Epoch [3/5], Batch [2400/3057], Loss: 0.2546\n",
            "Epoch [3/5], Batch [2500/3057], Loss: 0.7212\n",
            "Epoch [3/5], Batch [2600/3057], Loss: 0.5230\n",
            "Epoch [3/5], Batch [2700/3057], Loss: 0.4696\n",
            "Epoch [3/5], Batch [2800/3057], Loss: 0.4872\n",
            "Epoch [3/5], Batch [2900/3057], Loss: 0.3634\n",
            "Epoch [3/5], Batch [3000/3057], Loss: 0.5237\n",
            "Epoch [3/5] Average Loss: 0.4527, 975.95 seconds\n",
            "Epoch [4/5], Batch [0/3057], Loss: 0.6347\n",
            "Epoch [4/5], Batch [100/3057], Loss: 0.3361\n",
            "Epoch [4/5], Batch [200/3057], Loss: 0.2694\n",
            "Epoch [4/5], Batch [300/3057], Loss: 0.2846\n",
            "Epoch [4/5], Batch [400/3057], Loss: 0.5330\n",
            "Epoch [4/5], Batch [500/3057], Loss: 0.4050\n",
            "Epoch [4/5], Batch [600/3057], Loss: 0.3746\n",
            "Epoch [4/5], Batch [700/3057], Loss: 0.3255\n",
            "Epoch [4/5], Batch [800/3057], Loss: 0.3459\n",
            "Epoch [4/5], Batch [900/3057], Loss: 0.4941\n",
            "Epoch [4/5], Batch [1000/3057], Loss: 0.4706\n",
            "Epoch [4/5], Batch [1100/3057], Loss: 0.4606\n",
            "Epoch [4/5], Batch [1200/3057], Loss: 0.5948\n",
            "Epoch [4/5], Batch [1300/3057], Loss: 0.6378\n",
            "Epoch [4/5], Batch [1400/3057], Loss: 0.4979\n",
            "Epoch [4/5], Batch [1500/3057], Loss: 0.6028\n",
            "Epoch [4/5], Batch [1600/3057], Loss: 0.3280\n",
            "Epoch [4/5], Batch [1700/3057], Loss: 0.5319\n",
            "Epoch [4/5], Batch [1800/3057], Loss: 0.5095\n",
            "Epoch [4/5], Batch [1900/3057], Loss: 0.5647\n",
            "Epoch [4/5], Batch [2000/3057], Loss: 0.5053\n",
            "Epoch [4/5], Batch [2100/3057], Loss: 0.3689\n",
            "Epoch [4/5], Batch [2200/3057], Loss: 0.5292\n",
            "Epoch [4/5], Batch [2300/3057], Loss: 0.6229\n",
            "Epoch [4/5], Batch [2400/3057], Loss: 0.4260\n",
            "Epoch [4/5], Batch [2500/3057], Loss: 0.6108\n",
            "Epoch [4/5], Batch [2600/3057], Loss: 0.3041\n",
            "Epoch [4/5], Batch [2700/3057], Loss: 0.4498\n",
            "Epoch [4/5], Batch [2800/3057], Loss: 0.4717\n",
            "Epoch [4/5], Batch [2900/3057], Loss: 0.5893\n",
            "Epoch [4/5], Batch [3000/3057], Loss: 0.3976\n",
            "Epoch [4/5] Average Loss: 0.4449, 954.43 seconds\n",
            "Epoch [5/5], Batch [0/3057], Loss: 0.4425\n",
            "Epoch [5/5], Batch [100/3057], Loss: 0.4545\n",
            "Epoch [5/5], Batch [200/3057], Loss: 0.3822\n",
            "Epoch [5/5], Batch [300/3057], Loss: 0.4022\n",
            "Epoch [5/5], Batch [400/3057], Loss: 0.6199\n",
            "Epoch [5/5], Batch [500/3057], Loss: 0.7911\n",
            "Epoch [5/5], Batch [600/3057], Loss: 0.2748\n",
            "Epoch [5/5], Batch [700/3057], Loss: 0.3482\n",
            "Epoch [5/5], Batch [800/3057], Loss: 0.5709\n",
            "Epoch [5/5], Batch [900/3057], Loss: 0.5490\n",
            "Epoch [5/5], Batch [1000/3057], Loss: 0.3421\n",
            "Epoch [5/5], Batch [1100/3057], Loss: 0.3156\n",
            "Epoch [5/5], Batch [1200/3057], Loss: 0.7794\n",
            "Epoch [5/5], Batch [1300/3057], Loss: 0.4365\n",
            "Epoch [5/5], Batch [1400/3057], Loss: 0.3802\n",
            "Epoch [5/5], Batch [1500/3057], Loss: 0.4845\n",
            "Epoch [5/5], Batch [1600/3057], Loss: 0.7335\n",
            "Epoch [5/5], Batch [1700/3057], Loss: 0.6317\n",
            "Epoch [5/5], Batch [1800/3057], Loss: 0.5577\n",
            "Epoch [5/5], Batch [1900/3057], Loss: 0.2247\n",
            "Epoch [5/5], Batch [2000/3057], Loss: 0.3139\n",
            "Epoch [5/5], Batch [2100/3057], Loss: 0.4199\n",
            "Epoch [5/5], Batch [2200/3057], Loss: 0.5816\n",
            "Epoch [5/5], Batch [2300/3057], Loss: 0.4514\n",
            "Epoch [5/5], Batch [2400/3057], Loss: 0.2336\n",
            "Epoch [5/5], Batch [2500/3057], Loss: 0.3820\n",
            "Epoch [5/5], Batch [2600/3057], Loss: 0.2551\n",
            "Epoch [5/5], Batch [2700/3057], Loss: 0.1831\n",
            "Epoch [5/5], Batch [2800/3057], Loss: 0.3562\n",
            "Epoch [5/5], Batch [2900/3057], Loss: 0.4791\n",
            "Epoch [5/5], Batch [3000/3057], Loss: 0.5552\n",
            "Epoch [5/5] Average Loss: 0.4397, 947.78 seconds\n",
            "Training completed.\n",
            "Evaluating model...\n",
            "EVALUATING ViT model\n",
            "✅ Accuracy: 0.8020 | MRR: 0.7832 | Test Time: 110.50s\n",
            "📊 Results logged to results.csv\n",
            "✅ Model saved as itm_model_vit.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 main.py --arch MLP --pretrained --epochs 5 --batch_size 16"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKp_ZjvS0AuK",
        "outputId": "f633f3b9-5a88-41d2-cb73-3ace8a4ec1e7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading sentence embeddings...\n",
            "READING sentence embeddings...\n",
            "Preparing datasets and dataloaders...\n",
            "LOADING data from v7w.TrainImages.itm.txt\n",
            "=========================================\n",
            "|image_data|=48904\n",
            "|question_data|=48904\n",
            "|answer_data|=48904\n",
            "done loading data...\n",
            "LOADING data from v7w.TestImages.itm.txt\n",
            "=========================================\n",
            "|image_data|=5980\n",
            "|question_data|=5980\n",
            "|answer_data|=5980\n",
            "done loading data...\n",
            "Initializing model...\n",
            "BUILDING MLP model, pretrained=True\n",
            "Starting training...\n",
            "TRAINING MLP model\n",
            "Epoch [1/5], Batch [0/3057], Loss: 0.7708\n",
            "Epoch [1/5], Batch [100/3057], Loss: 0.9443\n",
            "Epoch [1/5], Batch [200/3057], Loss: 1.0110\n",
            "Epoch [1/5], Batch [300/3057], Loss: 0.8625\n",
            "Epoch [1/5], Batch [400/3057], Loss: 1.0017\n",
            "Epoch [1/5], Batch [500/3057], Loss: 1.2244\n",
            "Epoch [1/5], Batch [600/3057], Loss: 0.6009\n",
            "Epoch [1/5], Batch [700/3057], Loss: 1.0973\n",
            "Epoch [1/5], Batch [800/3057], Loss: 0.7258\n",
            "Epoch [1/5], Batch [900/3057], Loss: 0.6148\n",
            "Epoch [1/5], Batch [1000/3057], Loss: 0.7854\n",
            "Epoch [1/5], Batch [1100/3057], Loss: 0.6438\n",
            "Epoch [1/5], Batch [1200/3057], Loss: 0.3672\n",
            "Epoch [1/5], Batch [1300/3057], Loss: 0.5474\n",
            "Epoch [1/5], Batch [1400/3057], Loss: 0.6504\n",
            "Epoch [1/5], Batch [1500/3057], Loss: 0.4655\n",
            "Epoch [1/5], Batch [1600/3057], Loss: 0.4782\n",
            "Epoch [1/5], Batch [1700/3057], Loss: 0.6902\n",
            "Epoch [1/5], Batch [1800/3057], Loss: 0.4771\n",
            "Epoch [1/5], Batch [1900/3057], Loss: 0.5010\n",
            "Epoch [1/5], Batch [2000/3057], Loss: 0.6873\n",
            "Epoch [1/5], Batch [2100/3057], Loss: 0.5240\n",
            "Epoch [1/5], Batch [2200/3057], Loss: 0.8092\n",
            "Epoch [1/5], Batch [2300/3057], Loss: 0.5785\n",
            "Epoch [1/5], Batch [2400/3057], Loss: 0.5758\n",
            "Epoch [1/5], Batch [2500/3057], Loss: 0.5764\n",
            "Epoch [1/5], Batch [2600/3057], Loss: 0.4823\n",
            "Epoch [1/5], Batch [2700/3057], Loss: 0.4719\n",
            "Epoch [1/5], Batch [2800/3057], Loss: 0.5692\n",
            "Epoch [1/5], Batch [2900/3057], Loss: 0.3937\n",
            "Epoch [1/5], Batch [3000/3057], Loss: 0.5720\n",
            "Epoch [1/5] Average Loss: 0.6583, 187.65 seconds\n",
            "Epoch [2/5], Batch [0/3057], Loss: 0.4042\n",
            "Epoch [2/5], Batch [100/3057], Loss: 0.3893\n",
            "Epoch [2/5], Batch [200/3057], Loss: 0.8946\n",
            "Epoch [2/5], Batch [300/3057], Loss: 0.5380\n",
            "Epoch [2/5], Batch [400/3057], Loss: 0.6402\n",
            "Epoch [2/5], Batch [500/3057], Loss: 0.6108\n",
            "Epoch [2/5], Batch [600/3057], Loss: 0.3241\n",
            "Epoch [2/5], Batch [700/3057], Loss: 0.4943\n",
            "Epoch [2/5], Batch [800/3057], Loss: 0.4876\n",
            "Epoch [2/5], Batch [900/3057], Loss: 0.3761\n",
            "Epoch [2/5], Batch [1000/3057], Loss: 0.3825\n",
            "Epoch [2/5], Batch [1100/3057], Loss: 0.6289\n",
            "Epoch [2/5], Batch [1200/3057], Loss: 0.4648\n",
            "Epoch [2/5], Batch [1300/3057], Loss: 0.4910\n",
            "Epoch [2/5], Batch [1400/3057], Loss: 0.5938\n",
            "Epoch [2/5], Batch [1500/3057], Loss: 0.6064\n",
            "Epoch [2/5], Batch [1600/3057], Loss: 0.2913\n",
            "Epoch [2/5], Batch [1700/3057], Loss: 0.5474\n",
            "Epoch [2/5], Batch [1800/3057], Loss: 0.2840\n",
            "Epoch [2/5], Batch [1900/3057], Loss: 0.4363\n",
            "Epoch [2/5], Batch [2000/3057], Loss: 0.4816\n",
            "Epoch [2/5], Batch [2100/3057], Loss: 0.4821\n",
            "Epoch [2/5], Batch [2200/3057], Loss: 0.3799\n",
            "Epoch [2/5], Batch [2300/3057], Loss: 0.4501\n",
            "Epoch [2/5], Batch [2400/3057], Loss: 0.3892\n",
            "Epoch [2/5], Batch [2500/3057], Loss: 0.3926\n",
            "Epoch [2/5], Batch [2600/3057], Loss: 0.5148\n",
            "Epoch [2/5], Batch [2700/3057], Loss: 0.5137\n",
            "Epoch [2/5], Batch [2800/3057], Loss: 0.5717\n",
            "Epoch [2/5], Batch [2900/3057], Loss: 0.6264\n",
            "Epoch [2/5], Batch [3000/3057], Loss: 0.5091\n",
            "Epoch [2/5] Average Loss: 0.4729, 183.45 seconds\n",
            "Epoch [3/5], Batch [0/3057], Loss: 0.3436\n",
            "Epoch [3/5], Batch [100/3057], Loss: 0.3357\n",
            "Epoch [3/5], Batch [200/3057], Loss: 0.4614\n",
            "Epoch [3/5], Batch [300/3057], Loss: 0.4626\n",
            "Epoch [3/5], Batch [400/3057], Loss: 0.5818\n",
            "Epoch [3/5], Batch [500/3057], Loss: 0.4338\n",
            "Epoch [3/5], Batch [600/3057], Loss: 0.6340\n",
            "Epoch [3/5], Batch [700/3057], Loss: 0.3152\n",
            "Epoch [3/5], Batch [800/3057], Loss: 0.4197\n",
            "Epoch [3/5], Batch [900/3057], Loss: 0.3897\n",
            "Epoch [3/5], Batch [1000/3057], Loss: 0.2996\n",
            "Epoch [3/5], Batch [1100/3057], Loss: 0.2193\n",
            "Epoch [3/5], Batch [1200/3057], Loss: 0.3215\n",
            "Epoch [3/5], Batch [1300/3057], Loss: 0.4557\n",
            "Epoch [3/5], Batch [1400/3057], Loss: 0.2534\n",
            "Epoch [3/5], Batch [1500/3057], Loss: 0.3589\n",
            "Epoch [3/5], Batch [1600/3057], Loss: 0.3857\n",
            "Epoch [3/5], Batch [1700/3057], Loss: 0.5579\n",
            "Epoch [3/5], Batch [1800/3057], Loss: 0.3773\n",
            "Epoch [3/5], Batch [1900/3057], Loss: 0.5404\n",
            "Epoch [3/5], Batch [2000/3057], Loss: 0.6190\n",
            "Epoch [3/5], Batch [2100/3057], Loss: 0.4353\n",
            "Epoch [3/5], Batch [2200/3057], Loss: 0.2990\n",
            "Epoch [3/5], Batch [2300/3057], Loss: 0.4110\n",
            "Epoch [3/5], Batch [2400/3057], Loss: 0.3004\n",
            "Epoch [3/5], Batch [2500/3057], Loss: 0.4196\n",
            "Epoch [3/5], Batch [2600/3057], Loss: 0.4226\n",
            "Epoch [3/5], Batch [2700/3057], Loss: 0.5176\n",
            "Epoch [3/5], Batch [2800/3057], Loss: 0.4306\n",
            "Epoch [3/5], Batch [2900/3057], Loss: 0.4121\n",
            "Epoch [3/5], Batch [3000/3057], Loss: 0.2405\n",
            "Epoch [3/5] Average Loss: 0.4553, 183.08 seconds\n",
            "Epoch [4/5], Batch [0/3057], Loss: 0.3031\n",
            "Epoch [4/5], Batch [100/3057], Loss: 0.5743\n",
            "Epoch [4/5], Batch [200/3057], Loss: 0.4386\n",
            "Epoch [4/5], Batch [300/3057], Loss: 0.4535\n",
            "Epoch [4/5], Batch [400/3057], Loss: 0.2733\n",
            "Epoch [4/5], Batch [500/3057], Loss: 0.3293\n",
            "Epoch [4/5], Batch [600/3057], Loss: 0.6386\n",
            "Epoch [4/5], Batch [700/3057], Loss: 0.3329\n",
            "Epoch [4/5], Batch [800/3057], Loss: 0.4198\n",
            "Epoch [4/5], Batch [900/3057], Loss: 0.2604\n",
            "Epoch [4/5], Batch [1000/3057], Loss: 0.5419\n",
            "Epoch [4/5], Batch [1100/3057], Loss: 0.4815\n",
            "Epoch [4/5], Batch [1200/3057], Loss: 0.5724\n",
            "Epoch [4/5], Batch [1300/3057], Loss: 0.3813\n",
            "Epoch [4/5], Batch [1400/3057], Loss: 0.2172\n",
            "Epoch [4/5], Batch [1500/3057], Loss: 0.7080\n",
            "Epoch [4/5], Batch [1600/3057], Loss: 0.5800\n",
            "Epoch [4/5], Batch [1700/3057], Loss: 0.3453\n",
            "Epoch [4/5], Batch [1800/3057], Loss: 0.4752\n",
            "Epoch [4/5], Batch [1900/3057], Loss: 0.4956\n",
            "Epoch [4/5], Batch [2000/3057], Loss: 0.5539\n",
            "Epoch [4/5], Batch [2100/3057], Loss: 0.3114\n",
            "Epoch [4/5], Batch [2200/3057], Loss: 0.5401\n",
            "Epoch [4/5], Batch [2300/3057], Loss: 0.4420\n",
            "Epoch [4/5], Batch [2400/3057], Loss: 0.3359\n",
            "Epoch [4/5], Batch [2500/3057], Loss: 0.4711\n",
            "Epoch [4/5], Batch [2600/3057], Loss: 0.1640\n",
            "Epoch [4/5], Batch [2700/3057], Loss: 0.4891\n",
            "Epoch [4/5], Batch [2800/3057], Loss: 0.4675\n",
            "Epoch [4/5], Batch [2900/3057], Loss: 0.2871\n",
            "Epoch [4/5], Batch [3000/3057], Loss: 0.2415\n",
            "Epoch [4/5] Average Loss: 0.4479, 184.63 seconds\n",
            "Epoch [5/5], Batch [0/3057], Loss: 0.4986\n",
            "Epoch [5/5], Batch [100/3057], Loss: 0.8095\n",
            "Epoch [5/5], Batch [200/3057], Loss: 0.4523\n",
            "Epoch [5/5], Batch [300/3057], Loss: 0.3636\n",
            "Epoch [5/5], Batch [400/3057], Loss: 0.4883\n",
            "Epoch [5/5], Batch [500/3057], Loss: 0.3924\n",
            "Epoch [5/5], Batch [600/3057], Loss: 0.8121\n",
            "Epoch [5/5], Batch [700/3057], Loss: 0.4988\n",
            "Epoch [5/5], Batch [800/3057], Loss: 0.3343\n",
            "Epoch [5/5], Batch [900/3057], Loss: 0.4441\n",
            "Epoch [5/5], Batch [1000/3057], Loss: 0.4958\n",
            "Epoch [5/5], Batch [1100/3057], Loss: 0.3832\n",
            "Epoch [5/5], Batch [1200/3057], Loss: 0.3852\n",
            "Epoch [5/5], Batch [1300/3057], Loss: 0.4192\n",
            "Epoch [5/5], Batch [1400/3057], Loss: 0.3987\n",
            "Epoch [5/5], Batch [1500/3057], Loss: 0.5727\n",
            "Epoch [5/5], Batch [1600/3057], Loss: 0.4953\n",
            "Epoch [5/5], Batch [1700/3057], Loss: 0.5257\n",
            "Epoch [5/5], Batch [1800/3057], Loss: 0.3798\n",
            "Epoch [5/5], Batch [1900/3057], Loss: 0.6215\n",
            "Epoch [5/5], Batch [2000/3057], Loss: 0.6571\n",
            "Epoch [5/5], Batch [2100/3057], Loss: 0.6834\n",
            "Epoch [5/5], Batch [2200/3057], Loss: 0.3162\n",
            "Epoch [5/5], Batch [2300/3057], Loss: 0.5035\n",
            "Epoch [5/5], Batch [2400/3057], Loss: 0.5797\n",
            "Epoch [5/5], Batch [2500/3057], Loss: 0.4388\n",
            "Epoch [5/5], Batch [2600/3057], Loss: 0.4406\n",
            "Epoch [5/5], Batch [2700/3057], Loss: 0.4879\n",
            "Epoch [5/5], Batch [2800/3057], Loss: 0.6353\n",
            "Epoch [5/5], Batch [2900/3057], Loss: 0.4183\n",
            "Epoch [5/5], Batch [3000/3057], Loss: 0.6126\n",
            "Epoch [5/5] Average Loss: 0.4431, 185.10 seconds\n",
            "Training completed.\n",
            "Evaluating model...\n",
            "EVALUATING MLP model\n",
            "✅ Accuracy: 0.8048 | MRR: 0.7807 | Test Time: 6.67s\n",
            "📊 Results logged to results.csv\n",
            "✅ Model saved as itm_model_mlp.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q1A5Y9fPeWyK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}